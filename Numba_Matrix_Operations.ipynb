{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLP9EYct/OIe/olmf/p/4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etfrer-yi/Numba-Accelerated-Matrix-Operations/blob/main/Numba_Matrix_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v21ySWG8U4RA"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gpu_matrix_wrapper(A, B, fn):\n",
        "  size = A.shape[0]\n",
        "  A_device = cuda.to_device(A)\n",
        "  B_device = cuda.to_device(B)\n",
        "  C_device = cuda.device_array((size, size))\n",
        "\n",
        "  blocks_per_grid, threads_per_block = size, size\n",
        "  fn[blocks_per_grid, threads_per_block](A_device, B_device, C_device)\n",
        "  cuda.synchronize()\n",
        "  return C_device.copy_to_host()"
      ],
      "metadata": {
        "id": "ijL8PGcFVEHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider: swapping x and y\n",
        "@cuda.jit\n",
        "def gpu_matrix_thread_add(A_device, B_device, C_device):\n",
        "  x, y = cuda.grid(2)\n",
        "  C_device[x][y] = A_device[x][y] + B_device[x][y]\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_matrix_thread_sub(A_device, B_device, C_device):\n",
        "  x, y = cuda.grid(2)\n",
        "  C_device[x][y] = A_device[x][y] - B_device[x][y]\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_matrix_thread_mult(A_device, B_device, C_device):\n",
        "  x, y = cuda.grid(2)\n",
        "  tmp = 0.\n",
        "  for k in range(C_device.shape[0]):\n",
        "    tmp += A_device[x][k] * B_device[k][y]\n",
        "  C_device[x][y] = tmp\n",
        "\n",
        "def gpu_matrix_add(A, B):\n",
        "  return gpu_matrix_wrapper(A, B, gpu_matrix_thread_add)\n",
        "\n",
        "def gpu_matrix_sub(A, B):\n",
        "  return gpu_matrix_wrapper(A, B, gpu_matrix_thread_sub)\n",
        "\n",
        "def gpu_matrix_mult(A, B):\n",
        "  return gpu_matrix_wrapper(A, B, gpu_matrix_thread_mult)"
      ],
      "metadata": {
        "id": "XKcbK9bCVENS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.randint(0, 5, size=(1024, 1024))\n",
        "B = np.random.randint(0, 5, size=(1024, 1024))"
      ],
      "metadata": {
        "id": "LkDqCr1eVEWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit cpu_C_add_res = np.add(A, B)\n",
        "%timeit cpu_C_sub_res = np.subtract(A, B)\n",
        "%timeit cpu_C_mult_res = np.multiply(A, B)"
      ],
      "metadata": {
        "id": "aXvARs4_rVi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit cpu_C_add_res = gpu_matrix_add(A, B)\n",
        "%timeit cpu_C_sub_res = gpu_matrix_sub(A, B)\n",
        "%timeit cpu_C_mult_res = gpu_matrix_mult(A, B)"
      ],
      "metadata": {
        "id": "Kst0mArtrWJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}